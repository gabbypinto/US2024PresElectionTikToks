{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def804d-8af2-4545-8b16-6296f9ebf9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_bar, theme, element_text, labs,coord_flip,scale_y_log10\n",
    "\n",
    "# Ensure reproducibility for language detection\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437ebd8-b355-4f34-a412-a86bd0c7b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "def process_texts(texts):\n",
    "    language_counts = defaultdict(int)\n",
    "    unknown_texts = 0\n",
    "    for text in texts:\n",
    "        if isinstance(text, str):\n",
    "            doc = nlp(text)\n",
    "            detected_language = detect_language(text)\n",
    "            if detected_language == \"unknown\":\n",
    "                unknown_texts += 1\n",
    "            language_counts[detected_language] += 1\n",
    "        # else:\n",
    "        #     print(f\"Skipping non-string value: {text} (type: {type(text)})\")\n",
    "\n",
    "    return language_counts, unknown_texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5075bc2-ac33-4d50-9535-9989f393f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptsFile=\"\" #insert the file path to the transcripts per video\n",
    "df = pd.read_csv(transcriptsFile) #read as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a57e1b-20bf-449c-81f9-47880f745a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "texts = df['voice_to_text'].tolist()\n",
    "\n",
    "# Filter out NaN values\n",
    "filtered_data = [x for x in texts if not (isinstance(x, float) and math.isnan(x)) and pd.isna(x)]\n",
    "\n",
    "language_counts,unknown_texts =  process_texts(texts)\n",
    "\n",
    "total_counts = sum(language_counts.values())\n",
    "\n",
    "print(f\"Language Counts: {dict(language_counts)}\")\n",
    "print(f\"Total Count: {total_counts}\")\n",
    "print(f\"Number of texts: {len(texts)}\")\n",
    "print(f\"Unknown texts: {unknown_texts}\")\n",
    "# assert total_counts == len(texts), \"Total counts do not match the number of texts\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2567d-cc26-4092-a518-a522991243b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#country labels and count\n",
    "lang_dict = {'en': 213608,'es': 7279, 'pl': 66, 'tl': 309, 'hr': 19, 'fr': 439, 'zh-cn': 159, 'nl': 95, 'sq': 39, 'ar': 195, 'fa': 10, 'af': 174, 'da': 57, 'id': 166, 'it': 219, 'ko': 119, 'ru': 461, 'pt': 338, 'sw': 80, 'ja': 171, 'so': 226, 'tr': 165, 'cy': 181, 'sv': 30, 'no': 88, 'unknown': 49, 'vi': 76, 'de': 312, 'cs': 12, 'et': 67, 'th': 11, 'ca': 23, 'hu': 8, 'uk': 1, 'ro': 33, 'sk': 23, 'fi': 24, 'lt': 4, 'ne': 1, 'sl': 17, 'bg': 3, 'mk': 1, 'ur': 2, 'lv': 2}\n",
    "\n",
    "#lang code --> full name\n",
    "language_map = {\n",
    "    'en': 'English', 'es': 'Spanish', 'pl': 'Polish', 'tl': 'Tagalog', 'hr': 'Croatian', \n",
    "    'fr': 'French', 'zh-cn': 'Chinese', 'nl': 'Dutch', 'sq': 'Albanian', 'ar': 'Arabic', \n",
    "    'fa': 'Persian', 'af': 'Afrikaans', 'da': 'Danish', 'id': 'Indonesian', 'it': 'Italian', \n",
    "    'ko': 'Korean', 'ru': 'Russian', 'pt': 'Portuguese', 'sw': 'Swahili', 'ja': 'Japanese', \n",
    "    'so': 'Somali', 'tr': 'Turkish', 'cy': 'Welsh', 'sv': 'Swedish', 'no': 'Norwegian', \n",
    "    'unknown': 'Unknown', 'vi': 'Vietnamese', 'de': 'German', 'cs': 'Czech', 'et': 'Estonian', \n",
    "    'th': 'Thai', 'ca': 'Catalan', 'hu': 'Hungarian', 'uk': 'Ukrainian', 'ro': 'Romanian', \n",
    "    'sk': 'Slovak', 'fi': 'Finnish', 'lt': 'Lithuanian', 'ne': 'Nepali', 'sl': 'Slovenian', \n",
    "    'bg': 'Bulgarian', 'mk': 'Macedonian', 'ur': 'Urdu', 'lv': 'Latvian'\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(list(lang_dict.items()), columns=['LanguageCode', 'Count'])\n",
    "df['Language'] = df['LanguageCode'].map(language_map)\n",
    "# Sort the DataFrame by 'Count' in descending order\n",
    "df = df.sort_values(by='Count', ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "#plot the distribution of languages in the transcript\n",
    "p = (ggplot(df, aes(x='reorder(Language, -Count)', y='Count'))\n",
    "     + geom_bar(stat='identity')\n",
    "     + coord_flip()\n",
    "     + scale_y_log10()\n",
    "     + theme(\n",
    "         axis_text_y=element_text(size=45), \n",
    "         axis_text_x=element_text(size=45),  \n",
    "         axis_title_x=element_text(size=60),  \n",
    "         axis_title_y=element_text(size=60),  \n",
    "         plot_title=element_text(size=70, face='bold'),  \n",
    "         panel_background=element_rect(fill='white'),\n",
    "         plot_background=element_rect(fill='white'),\n",
    "         figure_size=(32, 28)  # Increase figure size\n",
    "     )\n",
    "     + labs(title=\"\", x=\"Language\", y=\"Count\")\n",
    "     )\n",
    "\n",
    "p.save(\"languages.png\", dpi=500, limitsize=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
